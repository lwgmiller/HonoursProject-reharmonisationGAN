{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OysbUh7g3vQg",
        "outputId": "5fb0a6a0-8e92-40b0-8051-e8d393b02c58"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "#from ipywidgets import interact, IntSlider\n",
        "\n",
        "import os, os.path, shutil\n",
        "import zipfile\n",
        "import random\n",
        "import json\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pypianoroll\n",
        "import pretty_midi\n",
        "from pypianoroll import Multitrack, Track\n",
        "from tqdm import tqdm\n",
        "from livelossplot import PlotLosses\n",
        "from livelossplot.outputs import MatplotlibPlot\n",
        "\n",
        "#from google.colab import drive\n",
        "\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acf9V9g33vMh"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "n_tracks = 4  # number of tracks\n",
        "n_pitches = 83  # number of pitches\n",
        "lowest_pitch = 24  # MIDI note number of the lowest pitch\n",
        "n_samples_per_song = 8  # number of samples to extract from each song in the datset\n",
        "n_measures = 4  # number of measures per sample\n",
        "beat_resolution = 4  # temporal resolution of a beat (in timestep)\n",
        "programs = [0, 0, 0, 0]  # program number for each track\n",
        "is_drums = [False, False, False, False]  # drum indicator for each track\n",
        "track_names = ['Soprano', 'Alto', 'Tenor', 'Bass']  # name of each track\n",
        "tempo = 100\n",
        "\n",
        "measure_resolution = 4 * beat_resolution\n",
        "tempo_array = np.full((4 * 4 * measure_resolution, 1), tempo)\n",
        "\n",
        "# Training\n",
        "batch_size = 16\n",
        "latent_dim = 128\n",
        "n_steps = 1000\n",
        "\n",
        "# Sampling\n",
        "sample_interval = 10  # interval to run the sampler (in step)\n",
        "n_samples = 4\n",
        "\n",
        "#Directories\n",
        "!mkdir -p midiDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owyqg9IN3vJH"
      },
      "outputs": [],
      "source": [
        "\"\"\"Midi dataset.\"\"\"\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "from music21 import midi\n",
        "from music21 import converter\n",
        "from music21 import note, stream, duration, tempo\n",
        "\n",
        "\n",
        "class MidiDataset(Dataset):\n",
        "    \"\"\"MidiDataset.\n",
        "    Parameters\n",
        "    ----------\n",
        "    path: str\n",
        "        Path to dataset.\n",
        "    split: str, optional (default=\"train\")\n",
        "        Split of dataset.\n",
        "    n_bars: int, optional (default=2)\n",
        "        Number of bars.\n",
        "    n_steps_per_bar: int, optional (default=16)\n",
        "        Number of steps per bar.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        path: str,\n",
        "        split: str = \"train\",\n",
        "        n_bars: int = 8,\n",
        "        n_steps_per_bar: int = 16,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        self.n_bars = n_bars\n",
        "        self.n_steps_per_bar = n_steps_per_bar\n",
        "        dataset = np.load(path, allow_pickle=True, encoding=\"bytes\")[split]\n",
        "        self.data_binary, self.data_ints, self.data = self.__preprocess__(dataset)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return the number of samples in dataset.\"\"\"\n",
        "        return len(self.data_binary)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tensor:\n",
        "        \"\"\"Return one samples from dataset.\n",
        "        Parameters\n",
        "        ----------\n",
        "        index: int\n",
        "            Index of sample.\n",
        "        Returns\n",
        "        -------\n",
        "        Tensor:\n",
        "            Sample.\n",
        "        \"\"\"\n",
        "        return torch.from_numpy(self.data_binary[index]).float()\n",
        "\n",
        "    def __preprocess__(self, data: np.ndarray) -> Tuple[np.ndarray]:\n",
        "        \"\"\"Preprocess data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: np.ndarray\n",
        "            Data.\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[np.ndarray]:\n",
        "            Data binary, data ints, preprocessed data.\n",
        "        \"\"\"\n",
        "        data_ints = []\n",
        "        for x in data:\n",
        "            skip = True\n",
        "            skip_rows = 0\n",
        "            while skip:\n",
        "                if not np.any(np.isnan(x[skip_rows: skip_rows + 4])):\n",
        "                    skip = False\n",
        "                else:\n",
        "                    skip_rows += 4\n",
        "            #print(x.shape)\n",
        "            if self.n_bars * self.n_steps_per_bar < x.shape[0]:\n",
        "                data_ints.append(x[skip_rows: self.n_bars * self.n_steps_per_bar + skip_rows, :])\n",
        "        \n",
        "        \n",
        "        data_ints = np.array(data_ints)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        #print(data_ints.shape)\n",
        "        self.n_songs = data_ints.shape[0]\n",
        "        self.n_tracks = data_ints.shape[2]\n",
        "        data_ints = data_ints.reshape([self.n_songs, self.n_bars * self.n_steps_per_bar, self.n_tracks])\n",
        "        #print(data_ints.shape)\n",
        "        max_note = n_pitches\n",
        "        mask = np.isnan(data_ints)\n",
        "        data_ints[mask] = max_note + 1\n",
        "        max_note = max_note + 1\n",
        "        data_ints = data_ints.astype(int)\n",
        "        #print(data_ints.shape)\n",
        "        \n",
        "        num_classes = max_note + 1\n",
        "        data_binary = np.eye(num_classes)[data_ints]\n",
        "        data_binary[data_binary == 0] = -1\n",
        "        data_binary = np.delete(data_binary, max_note, -1)\n",
        "        data_binary = data_binary.transpose([0, 1, 3, 2])\n",
        "        #print(data_binary.shape)\n",
        "        return data_binary, data_ints, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0N9rEnT3u9-"
      },
      "outputs": [],
      "source": [
        "from pypianoroll.track import BinaryTrack\n",
        "def save_pianoroll_as_midi(dataset,\n",
        "                  programs=programs,\n",
        "                  track_names=track_names,\n",
        "                  is_drums=is_drums,\n",
        "                  tempo=tempo,           # in bpm\n",
        "                  beat_resolution=beat_resolution,  # number of time steps\n",
        "                  destination_path=\"/content/midiDataset/\"\n",
        "                  ):\n",
        "    data_ = []\n",
        "    sopData = []\n",
        "\n",
        "    for piece in dataset:\n",
        "\n",
        "      pianoroll = piece > 0\n",
        "\n",
        "      #print(pianoroll.shape)\n",
        "\n",
        "    # Reshape batched pianoroll array to a single pianoroll array\n",
        "      pianoroll_ = pianoroll.reshape((-1, pianoroll.shape[1], pianoroll.shape[2]))\n",
        "\n",
        "      #print(pianoroll_.shape)\n",
        "\n",
        "    # Create the tracks   \n",
        "      tracks = []\n",
        "      for idx in range(pianoroll_.shape[2]):\n",
        "          tracks.append(pypianoroll.BinaryTrack(\n",
        "            track_names[idx], programs[idx], is_drums[idx], pianoroll_[..., idx]))\n",
        "          \n",
        "      multitrack = pypianoroll.Multitrack(\n",
        "          tracks=tracks, tempo=tempo_array, resolution=beat_resolution)\n",
        "      \n",
        "      data_.append(multitrack)\n",
        "\n",
        "      melody = []\n",
        "      for idx in range(1):\n",
        "        melody.append(pypianoroll.BinaryTrack(\n",
        "            track_names[idx], programs[idx], is_drums[idx], pianoroll_[..., idx]))\n",
        "        \n",
        "        sMultitrack = pypianoroll.Multitrack(\n",
        "          tracks=melody, tempo=tempo_array, resolution=beat_resolution)\n",
        "        \n",
        "        sopData.append(sMultitrack)\n",
        "        \n",
        "      \n",
        "\n",
        "    #print(tracks[0])\n",
        "    #print(sData_)\n",
        "      #print(multitrack)\n",
        "\n",
        "    #melody = []\n",
        "    #for track in (sopData):\n",
        "      #melody.append(track)\n",
        "      \n",
        "      #sData_.append(sMultitrack)\n",
        "    #print(sMultitrack)\n",
        "    sopData[0].write('./midiDataset/test.mid')\n",
        "    print('Midi saved to ', destination_path)\n",
        "    print(tracks)\n",
        "    #print(sopData)\n",
        "\n",
        "    #print(data_)\n",
        "    return data_, sopData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wno9Wcf74Ert",
        "outputId": "ab16f203-5257-4c32-ecf4-4e67ee340f20"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "from numpy.core.fromnumeric import shape\n",
        "d = np.load(r\"C:\\Users\\lwgmi\\Documents\\GitHub\\HonoursProject-reharmonisationGAN\\Dataset\\Jsb16thSeparated.npz\", allow_pickle=True, encoding = 'latin1')\n",
        "\n",
        "path = (r\"C:\\Users\\lwgmi\\Documents\\GitHub\\HonoursProject-reharmonisationGAN\\Dataset\\Jsb16thSeparated.npz\")\n",
        "\n",
        "dataset = MidiDataset(path=path).data_binary\n",
        "\n",
        "train = d['train']\n",
        "test = d['test']\n",
        "valid = d['valid']\n",
        "\n",
        "#print(train[3])\n",
        "\n",
        "data, sData = save_pianoroll_as_midi(dataset)\n",
        "\n",
        "mEvalData = data[100:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Evaluate():\n",
        "\n",
        "    def __init__(self, piece: np.ndarray):\n",
        "\n",
        "        self.piece = piece\n",
        "        piece_unprocessed, pieceArr, Pianoroll = self.__PreProcess__(self.piece)\n",
        "\n",
        "        self.piece_signature_vector = []\n",
        "\n",
        "        self.piece_signature_vector.extend(\n",
        "            [self.Number_of_notes(piece_unprocessed)[1], \n",
        "            self.Occupation_Rate(Pianoroll),\n",
        "            self.Polyphonic_Rate(pieceArr, piece_unprocessed),\n",
        "            self.Pitch_Range_Descriptors(piece_unprocessed)[0],\n",
        "            self.Pitch_Range_Descriptors(piece_unprocessed)[1],\n",
        "            self.Pitch_Range_Descriptors(piece_unprocessed)[2],\n",
        "            self.Pitch_Range_Descriptors(piece_unprocessed)[3],\n",
        "            self.Pitch_Interval_Range(piece_unprocessed)[0],\n",
        "            self.Pitch_Interval_Range(piece_unprocessed)[1],\n",
        "            self.Pitch_Interval_Range(piece_unprocessed)[2],\n",
        "            self.Pitch_Interval_Range(piece_unprocessed)[3],\n",
        "            self.Note_Duration(piece_unprocessed)[0],\n",
        "            self.Note_Duration(piece_unprocessed)[1],\n",
        "            self.Note_Duration(piece_unprocessed)[2],\n",
        "            self.Note_Duration(piece_unprocessed)[3]\n",
        "            ])\n",
        "        \n",
        "\n",
        "\n",
        "    def __PreProcess__(self, piece: np.ndarray):\n",
        "\n",
        "        Pianoroll = piece.reshape(piece.shape[1], piece.shape[0], piece.shape[2])\n",
        "\n",
        "        sop = []\n",
        "        alt = []\n",
        "        ten = []\n",
        "        bass = []\n",
        "\n",
        "        piece_unprocessed = []\n",
        "\n",
        "        tPianoroll = (np.where(Pianoroll == True))\n",
        "\n",
        "        sop = tPianoroll[2][0:128] \n",
        "        piece_unprocessed.append(sop)\n",
        "        sop = [[i] for i in tPianoroll[2][0:128]]\n",
        "\n",
        "        alt = tPianoroll[2][128:256] \n",
        "        piece_unprocessed.append(alt)\n",
        "        alt = [[i] for i in tPianoroll[2][128:256]]\n",
        "\n",
        "        ten = tPianoroll[2][256:384] \n",
        "        piece_unprocessed.append(ten)\n",
        "        ten = [[i] for i in tPianoroll[2][256:384]]\n",
        "\n",
        "        bass = tPianoroll[2][384:512] \n",
        "        piece_unprocessed.append(bass)\n",
        "        bass = [[i] for i in tPianoroll[2][384:512]]\n",
        "\n",
        "        pieceArr = [s + a + t + b for s, a, t, b in zip(sop, alt, ten, bass)]\n",
        "        pieceArr = np.array(pieceArr)\n",
        "\n",
        "        return piece_unprocessed, pieceArr, Pianoroll\n",
        "\n",
        "\n",
        "\n",
        "    def Number_of_notes(self, piece_unprocessed: list):\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for track in piece_unprocessed:\n",
        "\n",
        "            note = False\n",
        "        \n",
        "\n",
        "            for i, x in enumerate(track):\n",
        "\n",
        "                pre = track[i-1]\n",
        "\n",
        "                if i == 0:\n",
        "                    pass\n",
        "\n",
        "                elif pre == x and note == False: \n",
        "\n",
        "                    count = count + 1     \n",
        "                    note = True\n",
        "\n",
        "                elif pre == x and note == True:\n",
        "                    pass\n",
        "\n",
        "                elif pre != x and note == True:\n",
        "                        note = False\n",
        "\n",
        "                elif i == 128 and pre == x and note == False:\n",
        "                    count = count + 1\n",
        "\n",
        "                elif i == 128 and pre == x and note == True:\n",
        "                    pass\n",
        "                \n",
        "        return count, count / 128\n",
        "\n",
        "\n",
        "\n",
        "    def Occupation_Rate(self, Pianoroll: np.ndarray):\n",
        "\n",
        "        occ_rate = 0\n",
        "\n",
        "        for step in Pianoroll:\n",
        "            if step.any() == True:\n",
        "                occ_rate = occ_rate + 1\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        return occ_rate / 128\n",
        "\n",
        "\n",
        "\n",
        "    def Polyphonic_Rate(self, pieceArr: np.ndarray, piece_unprocessed):\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for i, timestep in enumerate(pieceArr[0::2]):\n",
        "\n",
        "            pre = pieceArr[i - 1]\n",
        "\n",
        "            if np.array_equal(timestep, pre) == False:\n",
        "                count = count + 1\n",
        "\n",
        "            elif np.array_equal(timestep, pre) == True:\n",
        "                pass\n",
        "\n",
        "        return count / self.Number_of_notes(piece_unprocessed)[0]\n",
        "\n",
        "\n",
        "\n",
        "    def Pitch_Range_Descriptors(self, piece_unprocessed: list):#piece_unprocessed: list\n",
        "\n",
        "        piece_unprocessed_whole = (*piece_unprocessed[0], *piece_unprocessed[1], *piece_unprocessed[2], *piece_unprocessed[3])\n",
        "        \n",
        "        max_note = max(piece_unprocessed_whole)\n",
        "        min_note = min(piece_unprocessed_whole)\n",
        "    \n",
        "        mean = sum(piece_unprocessed_whole) / len(piece_unprocessed_whole)\n",
        "\n",
        "        std_dev = np.std(piece_unprocessed_whole)\n",
        "\n",
        "        return max_note / 127, min_note / 127, mean / 127, std_dev / 127\n",
        "\n",
        "\n",
        "\n",
        "    def Pitch_Interval_Range(self, piece_unprocessed: list):\n",
        "\n",
        "        interval = []\n",
        "\n",
        "        for track in piece_unprocessed:\n",
        "\n",
        "            note = False\n",
        "\n",
        "            for i, x in enumerate(track):\n",
        "\n",
        "                pre = track[i-1]\n",
        "\n",
        "                if i == 0 or i ==(len(track) -1):\n",
        "                    pass\n",
        "\n",
        "                elif pre == x and note == False: \n",
        "                #count = count + 1\n",
        "                    note = True\n",
        "\n",
        "                elif pre == x and note == True:\n",
        "                    pass\n",
        "\n",
        "                elif pre != x and note == True:\n",
        "\n",
        "                    interval.append(abs(pre - x))\n",
        "                    note = False\n",
        "\n",
        "        inv_max = max(interval)\n",
        "        inv_min = min(interval)\n",
        "    \n",
        "        inv_mean = sum(interval) / len(interval)\n",
        "\n",
        "        inv_std_dev = np.std(interval)\n",
        "\n",
        "        return inv_max / 127, inv_min / 127, inv_mean / 127, inv_std_dev / 127\n",
        "\n",
        "\n",
        "    def Note_Duration(self, piece_unprocessed: list):\n",
        "\n",
        "        duration = []\n",
        "\n",
        "        for track in piece_unprocessed:\n",
        "\n",
        "            count = 0\n",
        "                #print(duration)\n",
        "                #print(len(track) - 1)\n",
        "\n",
        "            for i, x in enumerate(track):\n",
        "\n",
        "                pre = track[i-1]\n",
        "\n",
        "                if i == 127:\n",
        "\n",
        "                    count = count + 1\n",
        "                    duration.append(count)\n",
        "\n",
        "                elif pre != x and count != 0: #and note == True:\n",
        "\n",
        "                    duration.append(count)\n",
        "                    count = 1\n",
        "            \n",
        "                else:\n",
        "                    if i == 0 or pre == x:\n",
        "                        count = count + 1\n",
        " \n",
        "        dur_max = max(duration)\n",
        "        dur_min = min(duration)\n",
        "    \n",
        "        dur_mean = sum(duration) / len(duration)\n",
        "\n",
        "        dur_std_dev = np.std(duration)\n",
        "            #print(duration)\n",
        "\n",
        "        return dur_max, dur_min, dur_mean, dur_std_dev\n",
        "\n",
        "        \n",
        "\n",
        "    def Mahalanobis_Distance(piece, mEvalData):\n",
        "\n",
        "        x = np.array([Evaluate(piece).piece_signature_vector])\n",
        "\n",
        "        mEvalVector = []\n",
        "\n",
        "        for song in mEvalData:\n",
        "\n",
        "            mPianoroll = song.stack()\n",
        "\n",
        "            mEvalVector.append(Evaluate(mPianoroll).piece_signature_vector)\n",
        "\n",
        "        mEvalVector = np.array(mEvalVector)\n",
        "\n",
        "        m = np.mean(mEvalVector, axis=0)\n",
        "\n",
        "        xMm = x - m\n",
        "\n",
        "        mEvalVector = np.transpose(mEvalVector)\n",
        "\n",
        "        covM = np.cov(mEvalVector, bias = False)\n",
        "\n",
        "        invCovM = np.linalg.inv(covM)\n",
        "\n",
        "        #np.set_printoptions(suppress= True)\n",
        "\n",
        "        tem = np.dot(xMm, invCovM)\n",
        "        tem2 = np.dot(tem, np.transpose(xMm))\n",
        "\n",
        "        mD = np.reshape(np.sqrt(tem2), -1)\n",
        "\n",
        "        return mD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mahaData = []\n",
        "\n",
        "for pianoroll in data[0:99]:\n",
        "\n",
        "    pianoroll = pianoroll.stack()\n",
        "\n",
        "    maha = Evaluate.Mahalanobis_Distance(pianoroll, mEvalData)\n",
        "\n",
        "    mahaData.append(maha[0])\n",
        "\n",
        "\n",
        "\n",
        "range = (0, 20)\n",
        "bins = 20\n",
        "\n",
        "print(mahaData)\n",
        "\n",
        "plt.hist(mahaData, bins, range, color = 'red', histtype = 'bar', rwidth = 0.8)\n",
        "\n",
        "plt.xlabel('Mahalanobis Distance')\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "mahaData = np.mean(mahaData)\n",
        "\n",
        "print(mahaData)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "EvaluationModel.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4fb75c82e2f068c42db7bc75917ecb0fedfd8ad129e0fc2d2c18ba183d5fdada"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('proj_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
